---
title: "SNMF on Data Simulated from an NMF model: Part II"
author: "Jason Willwerscheid"
date: "3/24/2022"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, comment = "#>")
```

Here I'd like to take a closer look at non-negative EBMF. In the [previous analysis](snmf_on_nmf.html), I showed that it does a very good job finding the "true" structure even in a more complex simulation scenario. There, I used the greedy + backfit algorithm with point-exponential priors. Peter Carbonetto raised the question of initialization: can we initialize using the `nnlm` solution and then refine via a `flashier` backfit? Relatedly, what does the greedy "initialization" look like? How does `flashier` get from the greedy fit to the "correct" backfit solution? Finally, Matthew Stephens suggested that it might be computationally advantageous to use point-exponential priors with mode to be estimated for loadings. Any non-zero modes can then be absorbed into a fixed mean loadings vector of ones. How does this approach compare to the results I've already obtained?

I use the same simulation function and a similar plot function to the previous analysis.

```{r sim_fn}
library(flashier)
library(tidyverse)

sim_data <- function(n = 100, 
                     p = 200, 
                     K = 6, 
                     L.nn = 10, 
                     F.nn = 20, 
                     se = 0.1, 
                     K.dense = 1, 
                     seed = 666) {
  set.seed(seed)
  
  LL <- matrix(rexp(n * K), nrow = n, ncol = K)
  FF <- matrix(rexp(p * K), nrow = p, ncol = K)
  
  # "Mean" factor.
  LL[, 1] <- 3
  
  # Additional sparse nonnegative factors.
  for (k in (K.dense + 1):K) {
    L.nn.idx <- seq((k - K.dense - 1) * L.nn + 1, (k - K.dense) * L.nn)
    F.nn.idx <- seq((k - K.dense - 1) * (F.nn / 2) + 1, (k + K.dense) * (F.nn / 2))
    LL[setdiff(1:n, L.nn.idx), k] <- 0
    FF[setdiff(1:p, F.nn.idx), k] <- 0
  }
  
  # Add normal noise.
  Y <- LL %*% t(FF) + rnorm(n * p, sd = se)
  
  # Add a constant (which can be absorbed by mean factor) to ensure nonnegativity.
  Y <- Y - min(Y)
  
  return(list(LL = LL, FF = FF, Y = Y))
}

plot_it <- function(simdat, snmf_res) {
  LL <- simdat$LL

  to_tibble <- function(mat, type) {
    mat <- scale(mat, center = FALSE, scale = apply(mat, 2, function(x) max(abs(x))))
    return(
      as_tibble(mat, .name_repair = "unique") %>%
        mutate(row = row_number()) %>%
        pivot_longer(!row, names_to = "k", values_to = "value") %>%
        add_column(type = type)     
    )
  }
  
  
  suppressMessages({
    tib <- to_tibble(simdat$LL, "True loadings") %>%
      bind_rows(to_tibble(simdat$FF, "True factors")) %>%
      bind_rows(to_tibble(snmf_res$L.pm, "EBMF loadings")) %>%
      bind_rows(to_tibble(snmf_res$F.pm, "EBMF factors")) %>%
      mutate(k = as.numeric(str_remove_all(k, "\\."))) %>%
      mutate(type = factor(type, levels = c(
        "True loadings", "EBMF loadings",
        "True factors", "EBMF factors"
      )))
  })
  
  ggplot(tib, aes(x = k, y = row, fill = value)) +
    geom_tile() +
    scale_fill_gradient2() +
    facet_wrap(~type, nrow = 2, ncol = 2, dir = "h", scales = "free") +
    theme_void()
 }
```

## Greedy fit

This fit is slightly different to the previous analysis is that I use a fixed "mean" vector of ones for the first vector of loadings.

The greedy fit appears as follows:

```{r greedy}
simdat <- sim_data(K = 8, se = 1, L.nn = 20, F.nn = 40, K.dense = 3)

ones <- matrix(1, nrow = nrow(simdat$Y), ncol = 1)
ls.soln <- t(solve(crossprod(ones), crossprod(ones, simdat$Y)))

greedy_res <- flash.init(simdat$Y) %>%
  flash.set.verbose(0) %>%
  flash.init.factors(init = list(ones, ls.soln)) %>%
  flash.fix.factors(kset = 1, mode = 1) %>%
  flash.add.greedy(
    Kmax = 7,
    ebnm.fn = ebnm::ebnm_point_exponential,
    init.fn = function(fl) init.fn.default(fl, dim.signs = c(1, 1))
  )

plot_it(simdat, greedy_res)
```

So it already captures the correct structure, but the loadings and factors are a bit "thinner" or sparser than they should be.

## Backfit from greedy

The results using greedy + backfit are as follows. (This method was used in the previous analysis.)

```{r bf}
bf_t <- system.time({
  bf_res <- greedy_res %>%
    flash.backfit()
})

plot_it(simdat, bf_res)
```

Very nice! And fast -- this backfit took only `r bf_t[3]` seconds.

## Backfit from NNLM

Recall from the previous analysis that the `nnlm` fit is not nearly as clean as the `flashier` fit. Can EBMF improve upon the `nnlm` results?

```{r nnlm_bf}
nnmf_res <- NNLM::nnmf(simdat$Y, init = list(W0 = ones), k = 7, verbose = 0)
nnlmbf_t <- system.time({
  nnlmbf_res <- flash.init(simdat$Y) %>%
    flash.set.verbose(0) %>%
    flash.init.factors(
      list(nnmf_res$W[, c(8, 1:7)], t(nnmf_res$H[c(8, 1:7), ])),
      ebnm.fn = ebnm::ebnm_point_exponential
    ) %>%
    flash.fix.factors(kset = 1, mode = 1) %>%
    flash.backfit()
})

plot_it(simdat, nnlmbf_res)
```

Still pretty good! Loadings are not exactly sparse, but close enough. This method does take a bit longer: this backfit took `r nnlmbf_t[3]` seconds.

## Point-exponential priors with non-zero shift

Can using point-exponential priors with a non-zero mode improve either the fit or the computation time? The greedy + backfit algorithm already works really well on this scenario, so I'll focus instead on backfitting the `nnlm` fit. 

```{r nzpe}
nzpe_t <- system.time({
  nzpe_res <- flash.init(simdat$Y) %>%
    flash.set.verbose(3) %>%
    flash.init.factors(
      list(nnmf_res$W[, c(8, 1:7)], t(nnmf_res$H[c(8, 1:7), ])),
      ebnm.fn = c(
        as.ebnm.fn(prior_family = "point_exponential", mode = "estimate"),
        ebnm::ebnm_point_exponential
      )
    ) %>%
    flash.fix.factors(kset = 1, mode = 1) %>%
    flash.backfit()
})

# Shift loadings for visualization purposes.
shifts <- sapply(nzpe_res$L.ghat[2:8], function(g) g$shift[1])
nzpe_res$L.pm[, 2:8] <- nzpe_res$L.pm[, 2:8] - rep(shifts, each = nrow(simdat$Y))

plot_it(simdat, nzpe_res)
```

I don't think that these more complicated priors help much in this case, either in terms of the fit or in terms of performance (this backfit took `r nzpe_t[3]` seconds). We should try again using a more complex scenario.
